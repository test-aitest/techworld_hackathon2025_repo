# iOS フロントエンド - 音声会話機能

OpenAI Realtime APIを使用したリアルタイム音声会話機能をiOSアプリに実装しました。

## 実装内容

### 新規ファイル

#### 1. AudioPlayer.swift
PCM16形式の音声データを再生するクラス。

**主要機能:**
- 24kHz PCM16モノラル音声の再生
- AVAudioEngineとAVAudioPlayerNodeを使用
- リアルタイムストリーミング再生対応

### 更新ファイル

#### 1. WebSocketManager.swift
音声データの送受信に対応。

**追加機能:**
- `onAudioDataReceived`: AI音声データ受信時のコールバック
- `onTranscriptReceived`: 文字起こしテキスト受信時のコールバック
- `onStatusReceived`: ステータスメッセージ受信時のコールバック
- `isAISpeaking`: AI発話状態の管理

#### 2. CanvasView.swift
音声会話UIの統合。

**追加機能:**
- AudioPlayerの統合
- マイクオン/オフボタン
- 接続状態インジケーター
- AI発話中インジケーター
- 文字起こしテキスト表示エリア

#### 3. MicrophoneManager.swift（既存）
既に24kHz PCM16対応済み。変更なし。

## 使用方法

### 1. バックエンドサーバーの起動

```bash
cd backend
# .envファイルにOPENAI_API_KEYを設定
npm run dev
```

サーバーが `ws://localhost:3000` で起動します。

### 2. iOSアプリの実行

1. Xcodeでプロジェクトを開く
2. ビルドして実行
3. アプリが自動的にWebSocketサーバーに接続
4. マイク権限を許可
5. 会話開始！

### 3. 操作方法

- **マイクボタン**: 音声入力のオン/オフを切り替え
- **接続状態**: 画面下部に表示（緑=接続中、赤=未接続）
- **AI応答**: 自動的に音声で再生され、テキストも表示されます

## アーキテクチャ

```
┌─────────────────────────────────────────┐
│         CanvasView (UI)                 │
├─────────────────────────────────────────┤
│ ┌─────────────┐  ┌──────────────────┐  │
│ │ Microphone  │  │  WebSocket       │  │
│ │ Manager     │→→│  Manager         │  │
│ └─────────────┘  └──────────────────┘  │
│                           ↓             │
│                  ┌──────────────────┐  │
│                  │  Audio Player    │  │
│                  └──────────────────┘  │
└─────────────────────────────────────────┘
         ↕ WebSocket (PCM16 audio)
┌─────────────────────────────────────────┐
│     Node.js Backend Server              │
├─────────────────────────────────────────┤
│  RealtimeService                        │
└─────────────────────────────────────────┘
         ↕ WebSocket
┌─────────────────────────────────────────┐
│     OpenAI Realtime API                 │
└─────────────────────────────────────────┘
```

## 音声フォーマット

| パラメータ | 値 |
|----------|-----|
| フォーマット | PCM16 (16-bit signed integer) |
| サンプリングレート | 24,000 Hz |
| チャンネル数 | 1 (モノラル) |
| バイトオーダー | リトルエンディアン |
| インターリーブ | なし |

## トラブルシューティング

### マイクが動作しない

1. **権限確認**: 設定 > プライバシー > マイク でアプリの権限を確認
2. **再起動**: アプリを再起動してみる
3. **ログ確認**: Xcodeのコンソールでエラーメッセージを確認

### WebSocketに接続できない

1. **サーバー確認**: バックエンドサーバーが起動しているか確認
2. **URL確認**: WebSocketManager.swiftのURL設定を確認
3. **ネットワーク**: シミュレーターの場合、localhostでアクセス可能か確認

### 音声が再生されない

1. **音量確認**: デバイスの音量を確認
2. **AudioSession**: 他のアプリが音声セッションを占有していないか確認
3. **ログ確認**: 音声データが受信されているか確認

### 音質が悪い

1. **ネットワーク**: WiFi接続を確認（モバイルデータは遅延が大きい）
2. **バッファサイズ**: MicrophoneManager.swiftのbufferSize調整
3. **フォーマット確認**: 24kHz PCM16が正しく設定されているか確認

## UI説明

### メイン画面（CanvasView）

```
┌─────────────────────────────────────────┐
│ [←] [→]  [🎤]  [▶] [60px] [🗑️]        │ ← ツールバー
├─────────────────────────────────────────┤
│                                         │
│                                         │
│         キャンバス（お絵描き）              │
│                                         │
│                                         │
├─────────────────────────────────────────┤
│ [🍌] AI会話           [●接続完了][🌊発話中]│
│                                         │
│  こんにちは！何かお手伝いできますか？        │
│                                         │
└─────────────────────────────────────────┘
```

### インジケーター

- **接続状態**: 緑の丸 = 接続中、赤の丸 = 未接続
- **AI発話中**: 🌊 + "発話中" = AIが話している
- **マイク状態**: 🎤 (赤) = 録音中、🎤/ (灰) = 停止中

## プロジェクトに追加する必要があるファイル

Xcodeプロジェクトに以下のファイルを追加してください:

1. `frontend/eigotchi/lib/AudioPlayer.swift` (新規作成済み)
2. `frontend/eigotchi/lib/WebSocketManager.swift` (更新済み)
3. `frontend/eigotchi/lib/MicrophoneManager.swift` (既存)
4. `frontend/eigotchi/CanvasView.swift` (更新済み)

## 必要な権限

Info.plist に以下の権限を追加（既存の場合は確認）:

```xml
<key>NSMicrophoneUsageDescription</key>
<string>音声会話機能にマイクを使用します</string>
```

## 今後の改善点

1. **エラーハンドリング**: より詳細なエラーメッセージとリカバリー
2. **接続管理**: 自動再接続機能
3. **音声品質**: ノイズキャンセリング、エコー除去
4. **UI改善**: 音声波形の可視化、会話履歴の保存
5. **設定画面**: サーバーURL、音量調整など

## パフォーマンス最適化

- **バッファリング**: 約100msごとに音声データを送信
- **ストリーミング**: リアルタイムで音声を再生
- **メモリ管理**: 適切なリソース解放とクリーンアップ

## セキュリティ

- **API Key**: プロダクション環境では環境変数またはKeychainで管理
- **通信**: 本番環境ではwss://（WebSocket Secure）を使用推奨
- **認証**: 必要に応じてトークンベース認証を追加

---

すべての実装が完了しました！バックエンドサーバーを起動してiOSアプリを実行すると、リアルタイムの音声会話が楽しめます 🎉
