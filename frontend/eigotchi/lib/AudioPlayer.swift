//
//  AudioPlayer.swift
//  eigotchi
//
//  Created for playing PCM16 audio from OpenAI Realtime API
//

import Foundation
import AVFoundation
import Combine

class AudioPlayer: NSObject, ObservableObject {
    @Published var isPlaying = false
    
    private var audioEngine: AVAudioEngine?
    private var playerNode: AVAudioPlayerNode?
    private var sourceFormat: AVAudioFormat? // 24kHz PCM16 mono (input)
    private var mixFormat: AVAudioFormat?    // Engine/MainMixer format (output)
    private var converter: AVAudioConverter?
    
    // PCM16 24kHz ãƒ¢ãƒãƒ©ãƒ«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
    private let sampleRate: Double = 24000
    private let channels: AVAudioChannelCount = 1
    
    override init() {
        super.init()
        setupAudioEngine()
    }
    
    private func setupAudioEngine() {
        do {
            // AVAudioSessionã‚’è¨­å®šï¼ˆéŒ²éŸ³ã¨å†ç”Ÿã‚’åŒæ™‚ã«è¡Œã†ï¼‰
            let audioSession = AVAudioSession.sharedInstance()
            try audioSession.setCategory(.playAndRecord, mode: .default, options: [.defaultToSpeaker, .allowBluetooth])
            try audioSession.setActive(true)

            // å…¥åŠ›ï¼ˆOpenAI Realtime ã‹ã‚‰ã® PCM16 24kHz ãƒ¢ãƒãƒ©ãƒ«ï¼‰ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
            guard let srcFormat = AVAudioFormat(
                commonFormat: .pcmFormatInt16,
                sampleRate: sampleRate,
                channels: channels,
                interleaved: false
            ) else {
                print("âŒ Failed to create source audio format")
                return
            }
            self.sourceFormat = srcFormat

            // AudioEngineã¨PlayerNodeã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
            let engine = AVAudioEngine()
            let player = AVAudioPlayerNode()

            engine.attach(player)

            // ãƒŸã‚­ã‚µãƒ¼ã®å…¥å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆãƒ‡ãƒã‚¤ã‚¹ã«åˆã‚ã›ãŸ Float32 / 44.1k or 48k ãªã©ï¼‰
            let mixerInputFormat = engine.mainMixerNode.inputFormat(forBus: 0)
            self.mixFormat = mixerInputFormat

            // ãƒŸã‚­ã‚µãƒ¼ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§æ¥ç¶šï¼ˆ24kHz ã‚’å¼·åˆ¶ã—ãªã„ï¼‰
            engine.connect(player, to: engine.mainMixerNode, format: mixerInputFormat)

            self.audioEngine = engine
            self.playerNode = player

            // ã‚¨ãƒ³ã‚¸ãƒ³ã‚’èµ·å‹•
            try engine.start()

            print("âœ… AudioPlayer initialized. source: \(srcFormat), mix: \(mixerInputFormat)")

        } catch {
            print("âŒ Failed to setup audio engine: \(error)")
        }
    }
    
    /// PCM16éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å†ç”Ÿ
    func play(pcmData: Data) {
        guard let srcFormat = sourceFormat,
              let playerNode = playerNode,
              let audioEngine = audioEngine,
              audioEngine.isRunning,
              let mixFormat = mixFormat else {
            print("âŒ AudioPlayer is not ready")
            return
        }

        // å…¥åŠ›PCM16ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ AVAudioPCMBuffer (source) ã‚’ä½œæˆ
        let frameLength = pcmData.count / 2 // 16bit = 2 bytes per sample (mono)

        guard let srcBuffer = AVAudioPCMBuffer(pcmFormat: srcFormat, frameCapacity: AVAudioFrameCount(frameLength)) else {
            print("âŒ Failed to create source audio buffer")
            return
        }

        srcBuffer.frameLength = AVAudioFrameCount(frameLength)

        // ãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒƒãƒ•ã‚¡ã«ã‚³ãƒ”ãƒ¼ï¼ˆnon-interleavedï¼‰
        pcmData.withUnsafeBytes { (rawBufferPointer: UnsafeRawBufferPointer) in
            guard let baseAddress = rawBufferPointer.baseAddress else { return }
            let int16Pointer = baseAddress.assumingMemoryBound(to: Int16.self)

            if let channelData = srcBuffer.int16ChannelData {
                let dst = channelData[0]
                dst.update(from: int16Pointer, count: Int(frameLength))
            }
        }

        // å¤‰æ›å™¨ï¼ˆ24k PCM16 mono -> mixer Float32 44.1k/48k etc.ï¼‰ã‚’ç”¨æ„
        guard let converter = AVAudioConverter(from: srcFormat, to: mixFormat) else {
            print("âŒ Failed to create audio converter")
            return
        }
        self.converter = converter

        // å‡ºåŠ›ãƒãƒƒãƒ•ã‚¡å®¹é‡ã‚’æ¦‚ç®—ï¼ˆã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆæ¯”ã§ä¸Šé™ã‚’è¦‹ç©ã‚‚ã‚‹ï¼‰
        let ratio = mixFormat.sampleRate / srcFormat.sampleRate
        let outFrameCapacity = AVAudioFrameCount(ceil(Double(srcBuffer.frameLength) * ratio))

        guard let outBuffer = AVAudioPCMBuffer(pcmFormat: mixFormat, frameCapacity: outFrameCapacity) else {
            print("âŒ Failed to create output audio buffer")
            return
        }

        var conversionError: NSError?
        var providedSource = false
        
        let status = converter.convert(to: outBuffer, error: &conversionError) { inNumPackets, outStatus -> AVAudioBuffer? in
            if providedSource {
                outStatus.pointee = .endOfStream
                return nil
            } else {
                providedSource = true
                outStatus.pointee = .haveData
                return srcBuffer
            }
        }

        // ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’ãƒã‚§ãƒƒã‚¯
        if status == .error {
            print("âŒ Audio conversion failed: \(conversionError?.localizedDescription ?? "unknown error")")
            return
        }
        
        if status == .inputRanDry {
            print("âš ï¸ Audio conversion: input ran dry")
            // ç¶šè¡Œå¯èƒ½ãªã®ã§è­¦å‘Šã®ã¿
        }

        // å®Ÿéš›ã«å¤‰æ›ã•ã‚ŒãŸãƒ•ãƒ¬ãƒ¼ãƒ æ•°ã‚’ frameLength ã«è¨­å®šï¼ˆconvert ãŒåŸ‹ã‚ã¦ã„ã‚‹ãŸã‚ï¼‰
        // outBuffer.frameLength ã¯ convert ã«ã‚ˆã‚Šè¨­å®šæ¸ˆã¿ã®ã¯ãšã ãŒã€å¿µã®ãŸã‚ clamp
        if outBuffer.frameLength == 0 {
            print("âš ï¸ Audio conversion resulted in 0 frames")
            return
        }
        outBuffer.frameLength = min(outBuffer.frameLength, outBuffer.frameCapacity)

        // ãƒãƒƒãƒ•ã‚¡ã‚’å†ç”Ÿ
        playerNode.scheduleBuffer(outBuffer) { [weak self] in
            DispatchQueue.main.async {
                self?.isPlaying = false
            }
        }

        // ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ãŒåœæ­¢ã—ã¦ã„ã‚‹å ´åˆã¯å†ç”Ÿé–‹å§‹
        if !playerNode.isPlaying {
            playerNode.play()
        }

        DispatchQueue.main.async {
            self.isPlaying = true
        }

        print("ğŸ”Š Playing audio: in=\(pcmData.count) bytes (\(frameLength) samples @ \(srcFormat.sampleRate)Hz) -> out=\(outBuffer.frameLength) frames @ \(mixFormat.sampleRate)Hz")
    }
    
    /// å†ç”Ÿã‚’åœæ­¢
    func stop() {
        playerNode?.stop()
        
        DispatchQueue.main.async {
            self.isPlaying = false
        }
        
        print("â¹ï¸ Audio playback stopped")
    }
    
    /// ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    func cleanup() {
        stop()
        audioEngine?.stop()
        audioEngine = nil
        playerNode = nil
        sourceFormat = nil
        mixFormat = nil
        converter = nil
        
        // AVAudioSessionã¯ä»–ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆï¼ˆãƒã‚¤ã‚¯ï¼‰ã‚‚ä½¿ç”¨ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ã€
        // ã“ã“ã§ã¯éã‚¢ã‚¯ãƒ†ã‚£ãƒ–åŒ–ã—ãªã„
        print("ğŸ§¹ AudioPlayer cleaned up")
    }
    
    deinit {
        cleanup()
    }
}
