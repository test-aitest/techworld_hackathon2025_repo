//
//  MouthAnimationView.swift
//  eigotchi
//
//  å£ã‚’ã±ãã±ãå‹•ã‹ã™ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ“ãƒ¥ãƒ¼
//

import SwiftUI
import PencilKit
import ImageIO

// GIFã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³è¡¨ç¤ºç”¨ã®UIViewRepresentable
struct GIFImageView: UIViewRepresentable {
    let gifName: String
    let isAnimating: Bool  // ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³åˆ¶å¾¡ç”¨

    func makeUIView(context: Context) -> UIImageView {
        let imageView = UIImageView()
        imageView.contentMode = .scaleAspectFit
        imageView.clipsToBounds = true
        return imageView
    }

    func updateUIView(_ uiView: UIImageView, context: Context) {
        guard let asset = NSDataAsset(name: gifName) else { return }

        if isAnimating {
            // ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³GIFã‚’è¡¨ç¤º
            if uiView.image?.images == nil {
                uiView.image = UIImage.gifImageWithData(asset.data)
            }
        } else {
            // é™æ­¢ç”»ï¼ˆæœ€åˆã®ãƒ•ãƒ¬ãƒ¼ãƒ ï¼‰ã‚’è¡¨ç¤º
            if let source = CGImageSourceCreateWithData(asset.data as CFData, nil),
               let cgImage = CGImageSourceCreateImageAtIndex(source, 0, nil) {
                uiView.image = UIImage(cgImage: cgImage)
            }
        }
    }
}

// UIImageæ‹¡å¼µ: GIFãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç”»åƒã‚’ç”Ÿæˆ
extension UIImage {
    static func gifImageWithData(_ data: Data) -> UIImage? {
        guard let source = CGImageSourceCreateWithData(data as CFData, nil) else {
            print("GIFã‚½ãƒ¼ã‚¹ã®ä½œæˆã«å¤±æ•—")
            return nil
        }

        return UIImage.animatedImageWithSource(source)
    }

    static func animatedImageWithSource(_ source: CGImageSource) -> UIImage? {
        let count = CGImageSourceGetCount(source)
        var images = [UIImage]()
        var duration: TimeInterval = 0.0

        for i in 0..<count {
            if let cgImage = CGImageSourceCreateImageAtIndex(source, i, nil) {
                let image = UIImage(cgImage: cgImage)
                images.append(image)

                // ãƒ•ãƒ¬ãƒ¼ãƒ ã®è¡¨ç¤ºæ™‚é–“ã‚’å–å¾—
                let frameDuration = UIImage.frameDuration(at: i, source: source)
                duration += frameDuration
            }
        }

        return UIImage.animatedImage(with: images, duration: duration)
    }

    static func frameDuration(at index: Int, source: CGImageSource) -> TimeInterval {
        var frameDuration: TimeInterval = 0.1 // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ

        guard let properties = CGImageSourceCopyPropertiesAtIndex(source, index, nil) as? [String: Any],
              let gifProperties = properties[kCGImagePropertyGIFDictionary as String] as? [String: Any] else {
            return frameDuration
        }

        if let delayTime = gifProperties[kCGImagePropertyGIFUnclampedDelayTime as String] as? TimeInterval {
            frameDuration = delayTime
        } else if let delayTime = gifProperties[kCGImagePropertyGIFDelayTime as String] as? TimeInterval {
            frameDuration = delayTime
        }

        return frameDuration
    }
}

/// ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã‚’ä½¿ç”¨ã™ã‚‹å£ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ“ãƒ¥ãƒ¼
struct MouthAnimationViewWithImage: View {
    let screenshot: UIImage
    let mouthDetection: MouthDetection?
    let openAIAPIKey: String?
    let onSpeechComplete: (() -> Void)?
    @Binding var userIsSpeaking: Bool  // ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè©±ã—ã¦ã„ã‚‹ã‹ã©ã†ã‹
    @Binding var isGIFAnimating: Bool  // GIFã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³åˆ¶å¾¡
    @State private var mouthScale: CGFloat = 1.0
    @State private var isAnimating = false
    @State private var showPromptMessage = false  // å‚¬ä¿ƒãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è¡¨ç¤º
    @State private var ttsService: OpenAITTSService?

    var body: some View {
        GeometryReader { geometry in
            ZStack {
                // æ¤œå‡ºã«ä½¿ã£ãŸã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã‚’è¡¨ç¤ºï¼ˆç”»é¢ã„ã£ã±ã„ã«ï¼‰
                Image(uiImage: screenshot)
                    .resizable()
                    .aspectRatio(contentMode: .fill)
                    .frame(width: geometry.size.width, height: geometry.size.height)
                    .clipped()
                    .zIndex(0)  // èƒŒæ™¯ãƒ¬ã‚¤ãƒ¤ãƒ¼

                // å£ã®éƒ¨åˆ†ã‚’æ¤œå‡ºã§ããŸå ´åˆã€ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’è¿½åŠ 
                if let mouth = mouthDetection {
                    // 1. å…ƒã®å£ã‚’ç™½ã§éš ã™
                    Rectangle()
                        .fill(Color.white)
                        .frame(
                            width: mouth.boundingBox.width * geometry.size.width,
                            height: mouth.boundingBox.height * geometry.size.height
                        )
                        .position(
                            x: mouth.boundingBox.midX * geometry.size.width,
                            y: mouth.boundingBox.midY * geometry.size.height
                        )
                        .zIndex(1)

                    // 2. ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã™ã‚‹å£ã‚’è¡¨ç¤º
                    MouthOverlayViewForImage(
                        screenshot: screenshot,
                        mouthBounds: mouth.boundingBox,
                        scale: mouthScale,
                        canvasSize: geometry.size,
                        isGIFAnimating: isGIFAnimating
                    )
                    .zIndex(2)
                }

                // å‚¬ä¿ƒãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆä¸‹éƒ¨ã‹ã‚‰è¡¨ç¤ºï¼‰- æœ€ä¸Šä½ãƒ¬ã‚¤ãƒ¤ãƒ¼
                if showPromptMessage {
                    VStack {
                        Spacer()

                        Image("prompt_speech_bubble")
                            .resizable()
                            .scaledToFit()
                            .frame(maxWidth: geometry.size.width * 0.8)
                            .shadow(color: .black.opacity(0.2), radius: 8, x: 0, y: 4)
                            .padding(.horizontal, 30)
                            .padding(.bottom, 60)
                    }
                    .zIndex(100)  // æœ€ä¸Šä½ãƒ¬ã‚¤ãƒ¤ãƒ¼ã«è¡¨ç¤º
                    .transition(.move(edge: .bottom).combined(with: .opacity))
                }
            }
        }
        .onAppear {
            startMouthAnimation()

//            // OpenAI TTSã§ã€Œã“ã‚“ã«ã¡ã¯ã€ã‚’å†ç”Ÿ
//            if let apiKey = openAIAPIKey {
//                ttsService = OpenAITTSService(apiKey: apiKey)
//                Task {
//                    do {
//                        try await ttsService?.speak(text: "ã“ã‚“ã«ã¡ã¯") {
//                            // éŸ³å£°å†ç”ŸãŒçµ‚äº†ã—ãŸã‚‰GIFã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’åœæ­¢ï¼ˆãƒ“ãƒ¥ãƒ¼ã¯è¡¨ç¤ºã—ãŸã¾ã¾ï¼‰
//                            self.isGIFAnimating = false
//
//                            // å°‘ã—å¾…ã£ã¦ã‹ã‚‰å‚¬ä¿ƒãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
//                            DispatchQueue.main.asyncAfter(deadline: .now() + 0.5) {
//                                withAnimation(.spring(response: 0.6, dampingFraction: 0.7)) {
//                                    self.showPromptMessage = true
//                                }
//
//                                // 5ç§’å¾Œã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è‡ªå‹•çš„ã«æ¶ˆã™
//                                DispatchQueue.main.asyncAfter(deadline: .now() + 5.0) {
//                                    withAnimation(.spring(response: 0.6, dampingFraction: 0.7)) {
//                                        self.showPromptMessage = false
//                                    }
//                                }
//                            }
//                        }
//                    } catch {
//                        print("TTS ã‚¨ãƒ©ãƒ¼: \(error)")
//                    }
//                }
//            }
        }
        .onDisappear {
            isAnimating = false
            ttsService?.stop()
        }
        .onChange(of: userIsSpeaking) { _, newValue in
            // ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè©±ã—å§‹ã‚ãŸã‚‰ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ¶ˆã™
            if newValue && showPromptMessage {
                withAnimation(.spring(response: 0.4, dampingFraction: 0.7)) {
                    showPromptMessage = false
                }
            }
        }
    }

    private func startMouthAnimation() {
        guard !isAnimating else { return }
        isAnimating = true

        // ã±ãã±ãã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆç¹°ã‚Šè¿”ã—ï¼‰
        withAnimation(.easeInOut(duration: 0.3).repeatForever(autoreverses: true)) {
            mouthScale = 0.7  // å£ã‚’å°‘ã—ç¸®ã‚ã‚‹ï¼ˆé–‰ã˜ã‚‹ï¼‰
        }
    }
}

/// GIFç”»åƒã‚’ä½¿ã£ãŸå£ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³
struct MouthOverlayViewForImage: View {
    let screenshot: UIImage
    let mouthBounds: CGRect  // æ­£è¦åŒ–åº§æ¨™ (0.0-1.0)
    let scale: CGFloat
    let canvasSize: CGSize
    let isGIFAnimating: Bool

    var body: some View {
        GeometryReader { geometry in
            // Assetsã‹ã‚‰GIFã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’èª­ã¿è¾¼ã¿
            GIFImageView(gifName: "animated_mouth2", isAnimating: isGIFAnimating)
                .frame(
                    width: mouthBounds.width * geometry.size.width,
                    height: mouthBounds.height * geometry.size.height
                )
                .scaleEffect(y: scale, anchor: .center)
                .position(
                    x: mouthBounds.midX * geometry.size.width,
                    y: mouthBounds.midY * geometry.size.height
                )
        }
    }
}

struct MouthAnimationView: View {
    let drawing: PKDrawing
    let mouthDetection: MouthDetection?
    let openAIAPIKey: String?
    let onSpeechComplete: (() -> Void)?
    @State private var mouthScale: CGFloat = 1.0
    @State private var isAnimating = false
    @State private var isGIFAnimating = true  // GIFã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³åˆ¶å¾¡
    @State private var ttsService: OpenAITTSService?

    var body: some View {
        GeometryReader { geometry in
            ZStack {
                // å…ƒã®æç”»å…¨ä½“ã‚’è¡¨ç¤º
                DrawingImageView(drawing: drawing)

                // å£ã®éƒ¨åˆ†ã‚’æ¤œå‡ºã§ããŸå ´åˆã€ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’è¿½åŠ 
                if let mouth = mouthDetection {
                    // ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¡¨ç¤ºï¼ˆonAppearã§ä¸€åº¦ã ã‘ï¼‰
                    // let _ = print("ğŸ¯ æ¤œå‡ºã•ã‚ŒãŸå£ã®ä½ç½®:")
                    // let _ = print("  - ä¸­å¿ƒX: \(mouth.boundingBox.midX) (ç”»é¢ä¸Š: \(mouth.boundingBox.midX * geometry.size.width)px)")
                    // let _ = print("  - ä¸­å¿ƒY: \(mouth.boundingBox.midY) (ç”»é¢ä¸Š: \(mouth.boundingBox.midY * geometry.size.height)px)")
                    // let _ = print("  - å¹…: \(mouth.boundingBox.width) (ç”»é¢ä¸Š: \(mouth.boundingBox.width * geometry.size.width)px)")
                    // let _ = print("  - é«˜ã•: \(mouth.boundingBox.height) (ç”»é¢ä¸Š: \(mouth.boundingBox.height * geometry.size.height)px)")
                    // let _ = print("  - ã‚­ãƒ£ãƒ³ãƒã‚¹ã‚µã‚¤ã‚º: \(geometry.size)")

                    // ãƒ‡ãƒãƒƒã‚°: æ¤œå‡ºé ˜åŸŸã‚’èµ¤ã„æ ã§è¡¨ç¤º
                    Rectangle()
                        .stroke(Color.red, lineWidth: 3)
                        .frame(
                            width: mouth.boundingBox.width * geometry.size.width,
                            height: mouth.boundingBox.height * geometry.size.height
                        )
                        .position(
                            x: mouth.boundingBox.midX * geometry.size.width,
                            y: mouth.boundingBox.midY * geometry.size.height
                        )

                    // 1. å…ƒã®å£ã‚’é’è‰²ã§éš ã™ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼šç™½â†’é’ã«å¤‰æ›´ã—ã¦è¦‹ã‚„ã™ãã™ã‚‹ï¼‰
                    Rectangle()
                        .fill(Color.blue.opacity(0.8))
                        .frame(
                            width: mouth.boundingBox.width * geometry.size.width,
                            height: mouth.boundingBox.height * geometry.size.height
                        )
                        .position(
                            x: mouth.boundingBox.midX * geometry.size.width,
                            y: mouth.boundingBox.midY * geometry.size.height
                        )

                    // 2. ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã™ã‚‹å£ã‚’è¡¨ç¤º
                    MouthOverlayView(
                        drawing: drawing,
                        mouthBounds: mouth.boundingBox,
                        scale: mouthScale,
                        canvasSize: geometry.size
                    )
                }
            }
        }
        .onAppear {
            startMouthAnimation()

            // OpenAI TTSã§ã€Œã“ã‚“ã«ã¡ã¯ã€ã‚’å†ç”Ÿ
//            if let apiKey = openAIAPIKey {
//                ttsService = OpenAITTSService(apiKey: apiKey)
//                Task {
//                    do {
//                        try await ttsService?.speak(text: "ã“ã‚“ã«ã¡ã¯") {
//                            // éŸ³å£°å†ç”ŸãŒçµ‚äº†ã—ãŸã‚‰ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’åœæ­¢ï¼ˆãƒ“ãƒ¥ãƒ¼ã¯è¡¨ç¤ºã—ãŸã¾ã¾ï¼‰
//                            self.isAnimating = false
//                        }
//                    } catch {
//                        print("TTS ã‚¨ãƒ©ãƒ¼: \(error)")
//                    }
//                }
//            }
        }
        .onDisappear {
            isAnimating = false
            ttsService?.stop()
        }
    }

    private func startMouthAnimation() {
        guard !isAnimating else { return }
        isAnimating = true

        // ã±ãã±ãã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆç¹°ã‚Šè¿”ã—ï¼‰
        withAnimation(.easeInOut(duration: 0.3).repeatForever(autoreverses: true)) {
            mouthScale = 0.7  // å£ã‚’å°‘ã—ç¸®ã‚ã‚‹ï¼ˆé–‰ã˜ã‚‹ï¼‰
        }
    }
}

/// PKDrawingã‚’ç”»åƒã¨ã—ã¦è¡¨ç¤ºã™ã‚‹ãƒ“ãƒ¥ãƒ¼
struct DrawingImageView: View {
    let drawing: PKDrawing

    var body: some View {
        let image = drawing.image(from: drawing.bounds, scale: UIScreen.main.scale)
        Image(uiImage: image)
            .resizable()
            .scaledToFit()
    }
}

/// å£ã®éƒ¨åˆ†ã«ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ã—ã¦ã€ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’é©ç”¨
struct MouthOverlayView: View {
    let drawing: PKDrawing
    let mouthBounds: CGRect  // æ­£è¦åŒ–åº§æ¨™ (0.0-1.0)
    let scale: CGFloat
    let canvasSize: CGSize

    var body: some View {
        GeometryReader { geometry in
            if let mouthImage = extractMouthImage() {
                Image(uiImage: mouthImage)
                    .resizable()
                    .scaledToFit()
                    .frame(
                        width: mouthBounds.width * geometry.size.width,
                        height: mouthBounds.height * geometry.size.height
                    )
                    .scaleEffect(y: scale, anchor: .center)
                    .position(
                        x: (mouthBounds.midX) * geometry.size.width,
                        y: (mouthBounds.midY) * geometry.size.height
                    )
                    // å…ƒã®æç”»ã‚’éš ã™ãŸã‚ã®ãƒ–ãƒ¬ãƒ³ãƒ‰ãƒ¢ãƒ¼ãƒ‰
                    .blendMode(.normal)
            }
        }
    }

    /// å£ã®é ˜åŸŸã ã‘ã‚’åˆ‡ã‚Šå‡ºã—ãŸç”»åƒã‚’ç”Ÿæˆ
    private func extractMouthImage() -> UIImage? {
        let fullImage = drawing.image(from: drawing.bounds, scale: UIScreen.main.scale)

        // æ­£è¦åŒ–åº§æ¨™ã‚’å®Ÿéš›ã®ãƒ”ã‚¯ã‚»ãƒ«åº§æ¨™ã«å¤‰æ›
        let imageSize = fullImage.size
        let pixelBounds = CGRect(
            x: mouthBounds.origin.x * imageSize.width,
            y: mouthBounds.origin.y * imageSize.height,
            width: mouthBounds.width * imageSize.width,
            height: mouthBounds.height * imageSize.height
        )

        // ç”»åƒã‹ã‚‰å£ã®éƒ¨åˆ†ã‚’åˆ‡ã‚Šå‡ºã—
        guard let cgImage = fullImage.cgImage?.cropping(to: pixelBounds) else {
            return nil
        }

        return UIImage(cgImage: cgImage)
    }
}

// å£ã‚’ã±ãã±ãã•ã›ã‚‹ãŸã‚ã®æ‹¡å¼µæ©Ÿèƒ½ã‚’æŒã¤CanvasView
struct AnimatedCanvasView: View {
    @Binding var canvasView: PKCanvasView
    @State private var mouthDetection: MouthDetection?
    @State private var isDetecting = false
    @State private var showAnimation = false
    @State private var geminiAPIKey: String = ""
    @State private var openAIAPIKey: String = ""

    var body: some View {
        ZStack {
            if showAnimation, let drawing = canvasView.drawing as PKDrawing? {
                MouthAnimationView(
                    drawing: drawing,
                    mouthDetection: mouthDetection,
                    openAIAPIKey: openAIAPIKey.isEmpty ? nil : openAIAPIKey,
                    onSpeechComplete: {
                        withAnimation {
                            showAnimation = false
                        }
                    }
                )
                .transition(.opacity)
            }
        }
    }

    func detectAndAnimate(apiKey: String) async {
        guard !isDetecting else { return }
        isDetecting = true
        defer { isDetecting = false }

        // Canvasæç”»ã‚’ç”»åƒã«å¤‰æ›
        let drawing = canvasView.drawing
        guard !drawing.bounds.isEmpty else {
            print("Drawing is empty")
            return
        }

        let image = drawing.image(from: drawing.bounds, scale: UIScreen.main.scale)

        // Gemini APIã§å£ã‚’æ¤œå‡º
        let service = GeminiService(apiKey: apiKey)
        do {
            if let detection = try await service.detectMouth(in: image) {
                await MainActor.run {
                    self.mouthDetection = detection
                    withAnimation {
                        self.showAnimation = true
                    }
                }
            } else {
                print("No mouth detected")
            }
        } catch {
            print("Error detecting mouth: \(error)")
        }
    }
}
