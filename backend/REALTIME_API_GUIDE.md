# OpenAI Realtime API å®Ÿè£…ã‚¬ã‚¤ãƒ‰

ã“ã®ã‚¬ã‚¤ãƒ‰ã§ã¯ã€OpenAI Realtime APIã‚’ä½¿ç”¨ã—ãŸãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°ä¼šè©±ã®å®Ÿè£…ã«ã¤ã„ã¦èª¬æ˜ã—ã¾ã™ã€‚

## å®Ÿè£…æ¸ˆã¿ã®æ©Ÿèƒ½

### ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ (Node.js/TypeScript)

#### 1. WebSocketã‚µãƒ¼ãƒãƒ¼ (`src/index.ts`)
- ãƒãƒ¼ãƒˆ3000ã§WebSocketã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•
- ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‹ã‚‰ã®æ¥ç¶šã‚’å—ã‘ä»˜ã‘
- ç’°å¢ƒå¤‰æ•°ã‹ã‚‰OpenAI API Keyã‚’èª­ã¿è¾¼ã¿

#### 2. RealtimeService (`src/services/realtimeService.ts`)
OpenAI Realtime APIã¨ã®é€šä¿¡ã‚’ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹:

**ä¸»è¦ãƒ¡ã‚½ãƒƒãƒ‰:**
- `connect()`: OpenAI Realtime APIã«æ¥ç¶š
- `sendAudioToOpenAI()`: ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‹ã‚‰ã®éŸ³å£°ã‚’APIã«é€ä¿¡
- `handleOpenAIMessage()`: APIã‹ã‚‰ã®å¿œç­”ã‚’å‡¦ç†

**å‡¦ç†ã™ã‚‹ã‚¤ãƒ™ãƒ³ãƒˆ:**
- `session.created`: ã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆå®Œäº†
- `input_audio_buffer.speech_started`: ç™ºè©±é–‹å§‹æ¤œå‡º
- `input_audio_buffer.speech_stopped`: ç™ºè©±çµ‚äº†æ¤œå‡º
- `response.audio.delta`: AIéŸ³å£°å¿œç­”ï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ï¼‰
- `response.audio_transcript.delta`: æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ï¼‰
- `response.done`: å¿œç­”å®Œäº†

#### 3. VoiceController (`src/controllers/voiceController.ts`)
ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¨ã®æ¥ç¶šã‚’ç®¡ç†:
- WebSocketæ¥ç¶šã®ç¢ºç«‹
- ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿ï¼ˆéŸ³å£°ï¼‰ã®å—ä¿¡ã¨è»¢é€
- ãƒ†ã‚­ã‚¹ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å‡¦ç†

## ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ‰‹é †

### 1. ç’°å¢ƒå¤‰æ•°ã®è¨­å®š

`.env` ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã€OpenAI API Keyã‚’è¨­å®š:

```bash
OPENAI_API_KEY=sk-proj-your-actual-api-key
PORT=3000
```

### 2. ã‚µãƒ¼ãƒãƒ¼ã®èµ·å‹•

```bash
cd backend
npm install
npm run dev
```

ã‚µãƒ¼ãƒãƒ¼ã¯ `ws://localhost:3000` ã§èµ·å‹•ã—ã¾ã™ã€‚

## ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå´ã®å®Ÿè£…ã‚¬ã‚¤ãƒ‰ (Swift/iOS)

### å¿…è¦ãªå¤‰æ›´

#### 1. éŸ³å£°ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®å¤‰æ›´

OpenAI Realtime APIã¯ **PCM16 (24kHz, ãƒ¢ãƒãƒ©ãƒ«)** ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚

ç¾åœ¨ã® `MicrophoneManager.swift` ã‚’æ›´æ–°:

```swift
private func setupAudioEngine() {
    let inputNode = audioEngine.inputNode
    let inputFormat = inputNode.outputFormat(forBus: 0)
    
    // PCM16 ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ (24kHz, ãƒ¢ãƒãƒ©ãƒ«, 16bit)
    guard let recordingFormat = AVAudioFormat(
        commonFormat: .pcmFormatInt16,
        sampleRate: 24000,
        channels: 1,
        interleaved: false
    ) else {
        print("Failed to create recording format")
        return
    }
    
    // ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¤‰æ›ç”¨ã®ã‚³ãƒ³ãƒãƒ¼ã‚¿ãƒ¼
    guard let converter = AVAudioConverter(from: inputFormat, to: recordingFormat) else {
        print("Failed to create audio converter")
        return
    }
    
    inputNode.installTap(onBus: 0, bufferSize: 4096, format: inputFormat) { [weak self] buffer, time in
        guard let self = self else { return }
        
        // å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‹ã‚‰24kHz PCM16ã«å¤‰æ›
        let convertedBuffer = AVAudioPCMBuffer(
            pcmFormat: recordingFormat,
            frameCapacity: AVAudioFrameCount(recordingFormat.sampleRate * Double(buffer.frameLength) / inputFormat.sampleRate)
        )!
        
        var error: NSError?
        let inputBlock: AVAudioConverterInputBlock = { inNumPackets, outStatus in
            outStatus.pointee = .haveData
            return buffer
        }
        
        converter.convert(to: convertedBuffer, error: &error, withInputFrom: inputBlock)
        
        if let error = error {
            print("Conversion error: \\(error)")
            return
        }
        
        self.processAudioBuffer(convertedBuffer)
    }
}
```

#### 2. WebSocketManagerã®æ›´æ–°

éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚­ã‚¹ãƒˆä¸¡æ–¹ã‚’å—ä¿¡ã§ãã‚‹ã‚ˆã†ã«æ›´æ–°:

```swift
private func receiveMessage() {
    webSocketTask?.receive { [weak self] result in
        guard let self = self else { return }
        
        switch result {
        case .success(let message):
            switch message {
            case .string(let text):
                // ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚„æ–‡å­—èµ·ã“ã—ã‚’å‡¦ç†
                self.handleTextMessage(text)
                
            case .data(let data):
                // AIéŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å—ä¿¡
                self.handleAudioData(data)
                
            @unknown default:
                break
            }
            
            self.receiveMessage() // æ¬¡ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å¾…ã¤
            
        case .failure(let error):
            print("Receive error: \\(error)")
        }
    }
}

private func handleTextMessage(_ text: String) {
    if let data = text.data(using: .utf8),
       let json = try? JSONSerialization.jsonObject(with: data) as? [String: Any],
       let type = json["type"] as? String {
        
        switch type {
        case "status":
            if let message = json["message"] as? String {
                print("Status: \\(message)")
            }
            
        case "transcript":
            if let text = json["text"] as? String,
               let isDone = json["isDone"] as? Bool {
                print("Transcript: \\(text) (done: \\(isDone))")
                // UIã«æ–‡å­—èµ·ã“ã—ã‚’è¡¨ç¤º
            }
            
        case "error":
            if let message = json["message"] as? String {
                print("Error: \\(message)")
            }
            
        default:
            print("Unknown message type: \\(type)")
        }
    }
}

private func handleAudioData(_ data: Data) {
    // PCM16ãƒ‡ãƒ¼ã‚¿ã‚’å—ä¿¡
    // AVAudioPlayerã¾ãŸã¯AudioQueueã§å†ç”Ÿ
    print("Received audio: \\(data.count) bytes")
    playAudioData(data)
}
```

#### 3. éŸ³å£°å†ç”Ÿã®å®Ÿè£…

å—ä¿¡ã—ãŸPCM16éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å†ç”Ÿ:

```swift
class AudioPlayer {
    private var audioQueue: AudioQueueRef?
    private let format: AVAudioFormat
    
    init() {
        // 24kHz, PCM16, ãƒ¢ãƒãƒ©ãƒ«
        format = AVAudioFormat(
            commonFormat: .pcmFormatInt16,
            sampleRate: 24000,
            channels: 1,
            interleaved: false
        )!
        setupAudioQueue()
    }
    
    func play(data: Data) {
        // PCM16ãƒ‡ãƒ¼ã‚¿ã‚’å†ç”Ÿ
        // AudioQueueã¾ãŸã¯AVAudioEngineã‚’ä½¿ç”¨
    }
}
```

## é€šä¿¡ãƒ•ãƒ­ãƒ¼

```
1. ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ â†’ ã‚µãƒ¼ãƒãƒ¼: WebSocketæ¥ç¶š
   â†“
2. ã‚µãƒ¼ãƒãƒ¼ â†’ OpenAI: Realtime APIæ¥ç¶š
   â†“
3. ã‚µãƒ¼ãƒãƒ¼ â†’ ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ: {"type": "status", "message": "æ¥ç¶šå®Œäº†"}
   â†“
4. ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ â†’ ã‚µãƒ¼ãƒãƒ¼: éŸ³å£°ãƒ‡ãƒ¼ã‚¿(PCM16, 24kHz)
   â†“
5. ã‚µãƒ¼ãƒãƒ¼ â†’ OpenAI: input_audio_buffer.append
   â†“
6. OpenAI: Voice Activity Detection (è‡ªå‹•ã§ç™ºè©±ã‚’æ¤œå‡º)
   â†“
7. OpenAI â†’ ã‚µãƒ¼ãƒãƒ¼: response.audio.delta (AIéŸ³å£°)
   â†“
8. ã‚µãƒ¼ãƒãƒ¼ â†’ ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ: éŸ³å£°ãƒ‡ãƒ¼ã‚¿(PCM16, 24kHz)
   â†“
9. ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ: éŸ³å£°ã‚’å†ç”Ÿ
```

## ãƒ†ã‚¹ãƒˆæ–¹æ³•

### 1. ã‚µãƒ¼ãƒãƒ¼ã®å‹•ä½œç¢ºèª

```bash
cd backend
npm run dev
```

ãƒ­ã‚°ã«ä»¥ä¸‹ãŒè¡¨ç¤ºã•ã‚Œã‚Œã°OK:
```
ğŸš€ WebSocket server is running on ws://localhost:3000
ğŸ”‘ OpenAI API Key: sk-proj-xxxxx...
```

### 2. ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæ¥ç¶šãƒ†ã‚¹ãƒˆ

iOSã‚¢ãƒ—ãƒªã‹ã‚‰æ¥ç¶šã—ã€ãƒ­ã‚°ã‚’ç¢ºèª:

**ã‚µãƒ¼ãƒãƒ¼ãƒ­ã‚°:**
```
ğŸ”Œ New WebSocket connection established
ğŸ”Œ æ–°ã—ã„WebSocketæ¥ç¶šã‚’å—ã‘ä»˜ã‘ã¾ã—ãŸ
âœ… OpenAI Realtime API ã«æ¥ç¶šã—ã¾ã—ãŸ
ğŸ“¤ ã‚»ãƒƒã‚·ãƒ§ãƒ³è¨­å®šã‚’é€ä¿¡ã—ã¾ã—ãŸ
```

**ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒ­ã‚°:**
```
WebSocket connection attempt started
Status: OpenAI Realtime API ã«æ¥ç¶šã—ã¾ã—ãŸ ğŸ‰
```

### 3. éŸ³å£°é€ä¿¡ãƒ†ã‚¹ãƒˆ

ãƒã‚¤ã‚¯ã§è©±ã—ã‹ã‘ã‚‹ã¨:

**ã‚µãƒ¼ãƒãƒ¼ãƒ­ã‚°:**
```
ğŸ¤ éŸ³å£°ãƒ‡ãƒ¼ã‚¿å—ä¿¡
ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: 8192 bytes (8.00 KB)
éŸ³å£°é•·ã•: 170.67 ms
ğŸ“¤ éŸ³å£°ãƒ‡ãƒ¼ã‚¿é€ä¿¡: 8192 bytes
```

### 4. AIå¿œç­”ãƒ†ã‚¹ãƒˆ

AIãŒå¿œç­”ã™ã‚‹ã¨:

**ã‚µãƒ¼ãƒãƒ¼ãƒ­ã‚°:**
```
ğŸ“¥ OpenAI ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: response.audio.delta
ğŸ“¤ ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«éŸ³å£°é€ä¿¡: 4800 bytes
```

## ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### OpenAI APIã«æ¥ç¶šã§ããªã„

**ç—‡çŠ¶:** `âŒ OpenAI WebSocket ã‚¨ãƒ©ãƒ¼`

**è§£æ±ºæ–¹æ³•:**
1. `.env` ã® `OPENAI_API_KEY` ã‚’ç¢ºèª
2. APIã‚­ãƒ¼ãŒæœ‰åŠ¹ã‹ç¢ºèª: https://platform.openai.com/api-keys
3. ã‚¢ã‚«ã‚¦ãƒ³ãƒˆæ®‹é«˜ã‚’ç¢ºèª

### éŸ³å£°ãŒé€ä¿¡ã•ã‚Œãªã„

**ç—‡çŠ¶:** ã‚µãƒ¼ãƒãƒ¼ã«éŸ³å£°ãƒ‡ãƒ¼ã‚¿ãŒå±Šã‹ãªã„

**è§£æ±ºæ–¹æ³•:**
1. ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®éŸ³å£°ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãŒPCM16, 24kHzã‹ç¢ºèª
2. WebSocketæ¥ç¶šãŒç¢ºç«‹ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
3. ãƒã‚¤ã‚¯ã®æ¨©é™ãŒè¨±å¯ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª

### éŸ³å£°ãŒå†ç”Ÿã•ã‚Œãªã„

**ç—‡çŠ¶:** ã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰éŸ³å£°ãŒå±ŠããŒå†ç”Ÿã•ã‚Œãªã„

**è§£æ±ºæ–¹æ³•:**
1. AudioPlayerãŒæ­£ã—ãå®Ÿè£…ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
2. éŸ³å£°ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ(PCM16, 24kHz)ãŒä¸€è‡´ã—ã¦ã„ã‚‹ã‹ç¢ºèª
3. ãƒ‡ãƒã‚¤ã‚¹ã®éŸ³é‡ã‚’ç¢ºèª

## æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

1. **UIã®æ”¹å–„**
   - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ–‡å­—èµ·ã“ã—è¡¨ç¤º
   - éŸ³å£°æ³¢å½¢ã®å¯è¦–åŒ–
   - ä¼šè©±å±¥æ­´ã®ä¿å­˜

2. **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–**
   - éŸ³å£°ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°ã®èª¿æ•´
   - ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã®å‰Šæ¸›

3. **æ©Ÿèƒ½è¿½åŠ **
   - ä¼šè©±ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®æ°¸ç¶šåŒ–
   - è¤‡æ•°ãƒ¦ãƒ¼ã‚¶ãƒ¼å¯¾å¿œ
   - ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­å®š

## å‚è€ƒãƒªãƒ³ã‚¯

- [OpenAI Realtime API Documentation](https://platform.openai.com/docs/guides/realtime)
- [WebSocket API (MDN)](https://developer.mozilla.org/en-US/docs/Web/API/WebSocket)
- [AVAudioEngine (Apple)](https://developer.apple.com/documentation/avfaudio/avaudioengine)
